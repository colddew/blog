---
title: 机器学习之图像识别浅析
date: 2018-02-06 23:50:00
updated: 2018-02-06 23:50:00
desc: 机器学习之图像识别浅析
keywords: 机器学习, 深度学习, 迁移学习, 图像识别, AI, TensorFlow
categories: 技术
tags: [机器学习, 深度学习, 迁移学习, 图像识别, AI, TensorFlow]
---

![image-classification ](/images/image-classification.jpg)

历时数月，第一个私人订制的图像分类模型终于训练出来了，过程很艰辛，结果也不完美，但对未知的探索有了希望却是让心欣喜的。

<!--more-->

AI领域水很深，各种专有名词多如牛毛，为了更加深刻的理解和做好图像识别需要站在更高的层面去审视现在做的事情。AI最近几年的突飞猛进很大程度是由于机器学习的突破，更具体的说是深度学习等理论和工程实践的发展。没有扎实的数学和算法理论基础研究机器学习会举步维艰，但随着Google等公司开源出TensorFlow等技术，也给工程技术人员创造了使用机器学习的机会。现在AI的应用领域很广泛，语音识别、文字识别、自然语言处理、人脸识别、图像识别、图像搜索等很多场景都有应用，图像识别需要解决三个基本问题：是什么（分类）、有没有和在哪儿（定位）、是多少（数值），而我们利用TF建模只是图像识别里的一个研究方向叫图像分类。

利用机器学习做图像分类的大致流程包括：首先收集图片，对图片进行分类打标签，然后选择模型进行训练，对训练的模型进行评估和调优，最后使用训练好的模型对图片进行预测。具体到我自己的建模过程，数据收集和整理的过程是最艰难的，准确地找到数量足够且高质量的图片很耗费时间，每个分类通过各种渠道收集几百张图片这就是对体力巨大的挑战，而且还要保证图片被正确地打上标签就需要你对植物识别具有一定的专业知识了，这也让人真实地感受到ImageNet数据集的价值。图片的多样性越丰富，包括不同的颜色、角度、光线、前景、背景等，训练出的模型识别率越高。然后我们使用了深度学习中的神经网络Inception v3帮助我们训练模型，不需要手动提取诸如颜色分布、几何形状、纹理等特征，只需要使用像素图像的特征转化为浮点数作为分类器的输入。为了节约训练时间，在Inception v3模型的基础上使用了迁移学习对Final Layer进行训练，而训练Inception v3模型使用的ImageNet数据集已经包括了一千多种和一百多万张图片。在TF训练的过程中会自动将样本集合按比例8:1:1拆分成训练集合、验证集合（用于迭代验证训练中的准确性）和测试集合（用于最终测试训练的准确性），还可以通过设置变形、剪切、调节亮度、镜像等参数增加训练的样本数。模型训练会在神经网络的每个抽象的层次上进行上千次甚至百万次计算，寻找像素之间的模式，最终被用于识别图片中包含什么物种。如果记住了图片中太多的噪声信息会导致只有遇到相似噪声的图片才能识别，模型就存在过度拟合的问题，另外训练模型过于复杂和训练数据有限也可能是导致过度拟合的原因，训练样本中抽取部分作为验证集合也是为了解决这个问题。通过TensorBoard可视化界面的输出可以了解模型的好坏，精度越高、交叉熵越小说明模型越好，然而通过调节训练参数去调优却是个需要不断积累经验的过程，需要在训练速度、数据规模和训练精度等方面做一些折中。模型建好后就可以使用样本集以外的图片进行预测了，这类似于数据库搜索的行为，预测结果是以多个样本标签和相似度的形式返回。

近日值得关注的是百度也开放了个性化图像模型的服务，对于工程技术人员使用AI又降低了要求，需要做的只是收集足够的数据和做好分类标签，然后打包提交给百度AI平台就可以帮你训练模型了，存在的缺陷就是训练周期可能比较长，另外需要通过API去调用训练好的模型，相较于本地调用需要一定的网络耗时，不过这样的服务已经大大降低了接入个性化AI的门槛。

134个物种、13726个样本、60.1%的测试精度，这个一个起点，找到更好更快地收集优质图片的途径是目前亟待攻克的难点。前路漫漫，坚持下去也许就会看到曙光。